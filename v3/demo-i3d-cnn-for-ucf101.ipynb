{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Evan Mazor\\code\\repos\\bite-recognition\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_docs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_hub\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhub\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_docs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m embed\n\u001b[0;32m      8\u001b[0m logging\u001b[38;5;241m.\u001b[39mset_verbosity(logging\u001b[38;5;241m.\u001b[39mERROR)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Some modules to help with reading the UCF101 dataset.\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_docs'"
     ]
    }
   ],
   "source": [
    "# TensorFlow and TF-Hub modules.\n",
    "from absl import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow_docs.vis import embed\n",
    "\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "# Some modules to help with reading the UCF101 dataset.\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import tempfile\n",
    "import ssl\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Some modules to display an animation using imageio.\n",
    "import imageio\n",
    "from IPython import display\n",
    "\n",
    "from urllib import request  # requires python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities to fetch videos from UCF101 dataset\n",
    "UCF_ROOT = \"https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/\"\n",
    "_VIDEO_LIST = None\n",
    "_CACHE_DIR = tempfile.mkdtemp()\n",
    "# As of July 2020, crcv.ucf.edu doesn't use a certificate accepted by the\n",
    "# default Colab environment anymore.\n",
    "unverified_context = ssl._create_unverified_context()\n",
    "\n",
    "def list_ucf_videos():\n",
    "  \"\"\"Lists videos available in UCF101 dataset.\"\"\"\n",
    "  global _VIDEO_LIST\n",
    "  if not _VIDEO_LIST:\n",
    "    index = request.urlopen(UCF_ROOT, context=unverified_context).read().decode(\"utf-8\")\n",
    "    videos = re.findall(\"(v_[\\w_]+\\.avi)\", index)\n",
    "    _VIDEO_LIST = sorted(set(videos))\n",
    "  return list(_VIDEO_LIST)\n",
    "\n",
    "def fetch_ucf_video(video):\n",
    "  \"\"\"Fetches a video and cache into local filesystem.\"\"\"\n",
    "  cache_path = os.path.join(_CACHE_DIR, video)\n",
    "  if not os.path.exists(cache_path):\n",
    "    urlpath = request.urljoin(UCF_ROOT, video)\n",
    "    print(\"Fetching %s => %s\" % (urlpath, cache_path))\n",
    "    data = request.urlopen(urlpath, context=unverified_context).read()\n",
    "    open(cache_path, \"wb\").write(data)\n",
    "  return cache_path\n",
    "\n",
    "# Utilities to open video files using CV2\n",
    "def crop_center_square(frame):\n",
    "  y, x = frame.shape[0:2]\n",
    "  min_dim = min(y, x)\n",
    "  start_x = (x // 2) - (min_dim // 2)\n",
    "  start_y = (y // 2) - (min_dim // 2)\n",
    "  return frame[start_y:start_y+min_dim,start_x:start_x+min_dim]\n",
    "\n",
    "def load_video(path, max_frames=0, resize=(224, 224)):\n",
    "  cap = cv2.VideoCapture(path)\n",
    "  frames = []\n",
    "  try:\n",
    "    while True:\n",
    "      ret, frame = cap.read()\n",
    "      if not ret:\n",
    "        break\n",
    "      frame = crop_center_square(frame)\n",
    "      frame = cv2.resize(frame, resize)\n",
    "      frame = frame[:, :, [2, 1, 0]]\n",
    "      frames.append(frame)\n",
    "\n",
    "      if len(frames) == max_frames:\n",
    "        break\n",
    "  finally:\n",
    "    cap.release()\n",
    "  return np.array(frames) / 255.0\n",
    "\n",
    "def to_gif(images):\n",
    "  converted_images = np.clip(images * 255, 0, 255).astype(np.uint8)\n",
    "  imageio.mimsave('./animation.gif', converted_images, duration=40)\n",
    "  return embed.embed_file('./animation.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the kinetics-400 action labels from the GitHub repository.\n",
    "KINETICS_URL = \"https://raw.githubusercontent.com/deepmind/kinetics-i3d/master/data/label_map.txt\"\n",
    "with request.urlopen(KINETICS_URL) as obj:\n",
    "  labels = [line.decode(\"utf-8\").strip() for line in obj.readlines()]\n",
    "print(\"Found %d labels.\" % len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of videos in the dataset.\n",
    "ucf_videos = list_ucf_videos()\n",
    "\n",
    "categories = {}\n",
    "for video in ucf_videos:\n",
    "  category = video[2:-12]\n",
    "  if category not in categories:\n",
    "    categories[category] = []\n",
    "  categories[category].append(video)\n",
    "print(\"Found %d videos in %d categories.\" % (len(ucf_videos), len(categories)))\n",
    "\n",
    "print(categories.keys())\n",
    "\n",
    "for category, sequences in categories.items():\n",
    "  summary = \", \".join(sequences[:2])\n",
    "  print(\"%-20s %4d videos (%s, ...)\" % (category, len(sequences), summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i3d = hub.load(\"https://tfhub.dev/deepmind/i3d-kinetics-400/1\").signatures['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sample_video):\n",
    "  # Add a batch axis to the sample video.\n",
    "  model_input = tf.constant(sample_video, dtype=tf.float32)[tf.newaxis, ...]\n",
    "\n",
    "  logits = i3d(model_input)['default'][0]\n",
    "  probabilities = tf.nn.softmax(logits)\n",
    "\n",
    "  print(\"Top 5 actions:\")\n",
    "  for i in np.argsort(probabilities)[::-1][:5]:\n",
    "    print(f\"  {labels[i]:22}: {probabilities[i] * 100:5.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the video.\n",
    "# video = fetch_ucf_video(\"v_BenchPress_g01_c01.avi\")\n",
    "video = 'test_vid_1.ogv'\n",
    "video = load_video(video, max_frames=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
